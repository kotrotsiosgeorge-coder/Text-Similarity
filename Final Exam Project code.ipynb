{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d66ef44f",
   "metadata": {},
   "source": [
    "# Final Exam Project\n",
    "## Foundations of Data Science: Programming and Linear Algebra\n",
    "### Rasmus Kongstad Thomsen (rath19ab) (137041)\n",
    "### Diana Laura Janikowski (dija20ab) (143003)\n",
    "### George Kotrotsios (geko22ac) (158283)\n",
    "### Jeno Toth (jeto22ac) (158386)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbde510",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403e891",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da1d793",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNumPy:\n",
    "    \n",
    "    #1)\n",
    "    #Define a function that takes an int parameter and returns a list of length Int\n",
    "    #containing the number 1 Int amount of times\n",
    "    def ones(Int):\n",
    "        if type(Int) != int:\n",
    "            return \"Input has to be integer!\"\n",
    "        else:\n",
    "            return [1 for i in range(Int)]\n",
    "    \n",
    "    \n",
    "    #2)\n",
    "    #The same concept as the function above, the only difference is the use of the number 0 instead of 1\n",
    "    def zeros(Int):\n",
    "        if type(Int) != int:\n",
    "            return \"Input has to be integer!\"\n",
    "        else:\n",
    "            return [0 for i in range(Int)]\n",
    "    \n",
    "    \n",
    "    #3)\n",
    "    #Define a function taking the following as parameters: array, number of rows and number of columns\n",
    "    #And reshaping the array into a matrix with dimensions according to the number of rows and columns\n",
    "    #Based on: https://www.youtube.com/watch?v=FF29bm8j6kQ\n",
    "    \n",
    "    \n",
    "    def reshape(array, row, column):\n",
    "        if type(row) == int:\n",
    "            if type(column) == int:\n",
    "                if row * column == len(array):        \n",
    "                    matrix = []\n",
    "                    for r in range(row):\n",
    "                        listrow = []\n",
    "                        for c in range(column):\n",
    "                            listrow.append(array[r * column + c])\n",
    "                        matrix.append(listrow)\n",
    "                    return matrix\n",
    "                else:\n",
    "                    return \"Cannot reshape array of size \" + str(len(array)) + \" into shape (\" + str(row) + \",\" + str(column) + \").\"\n",
    "            else:\n",
    "                return \"Row and column must be integers!\"\n",
    "        else:\n",
    "            return \"Row and column must be integers!\"\n",
    "    \n",
    "    #4)\n",
    "    def is_vector(array):\n",
    "        try:\n",
    "            array = array[0][0]\n",
    "        except TypeError:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    #Define a function taking an array as an argument and return its number of rows and columns\n",
    "    #Based on: https://www.pythonpool.com/list-shape-python/\n",
    "    def shape(array):\n",
    "        if type(array) == int:\n",
    "            rows = 1\n",
    "            columns = 1\n",
    "        else:\n",
    "            rows = len(array)         #Take the length of the array\n",
    "            if type(array[0]) == int:\n",
    "                columns = 1\n",
    "            else:\n",
    "                columns = len(array[0])   #Take the length of the first item in the array\n",
    "        shape = (rows, columns)\n",
    "        return shape\n",
    "    \n",
    "    \n",
    "    #5\n",
    "    #Define a function taking two arrays as arguments and return their combination\n",
    "    #Based on: https://www.geeksforgeeks.org/python-merge-two-list-of-lists-according-to-first-element/\n",
    "    def append(array1, array2):\n",
    "        shape1 = SNumPy.shape(array1)      #Get the shape of array1\n",
    "        shape2 = SNumPy.shape(array2)      #Get the shape of array2\n",
    "        #Check if the arrays have the same number of rows\n",
    "        if (shape1[0] == shape2[0]):\n",
    "            if SNumPy.is_vector(array1):\n",
    "                array1 = [array1]\n",
    "                array2 = [array2]\n",
    "            return [a + b for (a, b) in zip(array1, array2)]\n",
    "        else:\n",
    "            return \"The given arrays do not have the same number of rows.\"\n",
    "            \n",
    "            \n",
    "    #6\n",
    "    #Define a function taking an array as an argument and return the value specified by the row and column\n",
    "    def get(array, row, column):\n",
    "        value = [array[row - 1][column - 1]]\n",
    "        return value\n",
    "        \n",
    "        \n",
    "    #7)\n",
    "    #Define a function taking two arrays as arguments and return their sum\n",
    "    #Based on: https://www.youtube.com/watch?v=-sAmg3yoVhI\n",
    "    def add(array1, array2):\n",
    "        shape1 = SNumPy.shape(array1)      #Get the shape of array1\n",
    "        shape2 = SNumPy.shape(array2)      #Get the shape of array2\n",
    "        #Check if the arrays have the same shape\n",
    "        if (shape1[0] == shape2[0] and shape1[1] == shape2[1]):\n",
    "            if SNumPy.is_vector(array1):\n",
    "                array1 = [array1]\n",
    "                array2 = [array2]\n",
    "            #Create an array with 0s to be used for the final calculation based on the shape of the arrays\n",
    "            thesum = SNumPy.zeros(shape1[0] * shape1[1])              #Create a list with 0s\n",
    "            thesum = SNumPy.reshape(thesum, shape1[0], shape1[1])     #Reshape the list\n",
    "            for i in range(shape1[0]):\n",
    "                for k in range(shape1[1]):\n",
    "                    thesum[i][k] = array1[k][i] + array2[k][i]\n",
    "            return thesum\n",
    "        else:\n",
    "            return \"The shapes of the given arrays do not match.\"\n",
    "\n",
    "    #8)\n",
    "    #Define a function taking two arrays as arguments and return the difference\n",
    "    #Based on: https://www.youtube.com/watch?v=-sAmg3yoVhI\n",
    "    def subtract(array1, array2):\n",
    "        shape1 = SNumPy.shape(array1)      #Get the shape of array1\n",
    "        shape2 = SNumPy.shape(array2)      #Get the shape of array2\n",
    "        #Check if the arrays have the same shape\n",
    "        if (shape1[0] == shape2[0] and shape1[1] == shape2[1]):\n",
    "            if SNumPy.is_vector(array1):\n",
    "                array1 = [array1]\n",
    "                array2 = [array2]\n",
    "            #Create an array with 0s to be used for the final calculation based on the shape of the arrays\n",
    "            difference = SNumPy.zeros(shape1[0] * shape1[1])                  #Create a list with 0s\n",
    "            difference = SNumPy.reshape(difference, shape1[0], shape1[1])     #Reshape the list\n",
    "            for i in range(shape1[0]):\n",
    "                for k in range(shape1[1]):\n",
    "                    difference[i][k] = array1[k][i] - array2[k][i]\n",
    "            return difference\n",
    "        else:\n",
    "            return \"The shapes of the given arrays do not match.\"\n",
    "            \n",
    "        \n",
    "    #9)\n",
    "    #Define a function taking two arrays as arguments and return dot product\n",
    "    #Based on: https://stackoverflow.com/questions/66427420/multiplying-matrixes-without-numpy\n",
    "    def dotproduct(array1, array2):\n",
    "        shape1 = SNumPy.shape(array1)      #Get the shape of array1\n",
    "        shape2 = SNumPy.shape(array2)      #Get the shape of array2\n",
    "        #Check if the number of columns in array1 equals the number of rows in array2\n",
    "        if SNumPy.is_vector(array1):\n",
    "            array1 = [array1]\n",
    "        if SNumPy.is_vector(array2):\n",
    "            array2 = [array2]\n",
    "        if (shape1[1] == shape2[0]):\n",
    "            dotproduct = []\n",
    "            for m in range(0, len(array1)): \n",
    "                rows = []\n",
    "                for i in range(0, len(array2[0])): \n",
    "                    columns = 0\n",
    "                    for j in range (0, len(array2)): \n",
    "                        columns += array1[m][j] * array2[j][i]\n",
    "                    rows.append(columns) \n",
    "                dotproduct.append(rows) \n",
    "            return dotproduct\n",
    "        else:\n",
    "            return \"The number of columns in array1 does not equal the number of rows in array2.\"\n",
    "        \n",
    "    \n",
    "    #10)\n",
    "    #Solver for a system of linear equations using Gaussian elimination\n",
    "    #and row reduction rules for the functionality\n",
    "    #based on https://www.codesansar.com/numerical-methods/gauss-elimination-method-python-program.htm\n",
    "    def gaussian(a,b):\n",
    "        for i in range(1,len(a)):\n",
    "            if len(a[i]) != len(a[i-1]):\n",
    "                return \"All equations must contain the same number of unknowns. E.g. if equations are k*x_0 + l*x_1 = a, m*x_0 + n*x_1 = b, input arrays must be [[k,l],[m,n]] and [a,b]\"\n",
    "        if SNumPy.is_vector(b) != True:\n",
    "            return \"Right-hand side of the equations must be given as a vector. E.g. if equations are k*x_0 + l*x_1 = a, m*x_0 + n*x_1 = b, input arrays must be [[k,l],[m,n]] and [a,b]\"\n",
    "        elif len(b) != len(a):\n",
    "            return \"Same amount of equations must be given. E.g. if equations are k*x_0 + l*x_1 = a, m*x_0 + n*x_1 = b, input arrays must be [[k,l],[m,n]] and [a,b]\"\n",
    "        else:\n",
    "            for i in range(len(a)):\n",
    "                for j in range(len(a[0])):\n",
    "                    try:\n",
    "                        float(a[i][j])\n",
    "                    except ValueError:\n",
    "                        return \"Input must be integer or float!\"                        \n",
    "            for i in range(len(b)):\n",
    "                try:\n",
    "                    float(b[i])\n",
    "                except ValueError:\n",
    "                    return \"Input must be integer or float!\"\n",
    "                \n",
    "            m = SNumPy.reshape(snp.zeros(len(a)*len(a[0])+len(b)),len(a),len(a[0])+1)\n",
    "            n = SNumPy.zeros(len(a))\n",
    "            for i in range(len(a[0])):\n",
    "                for j in range(len(a)):\n",
    "                    m[i][j] = a[i][j]\n",
    "                m[i][j+1] = b[i]\n",
    "            for i in range(len(a)):\n",
    "                if m[i][i] == 0.0:\n",
    "                    return 'Divide by zero detected!'\n",
    "                for j in range(i+1, len(a)):\n",
    "                    ratio = m[j][i]/m[i][i]\n",
    "                    for k in range(len(a)+1):\n",
    "                        m[j][k] = m[j][k] - ratio * m[i][k]\n",
    "            n[len(a)-1] = m[len(a)-1][len(a)]/m[len(a)-1][len(a)-1]\n",
    "\n",
    "            for i in range(len(a)-2,-1,-1):\n",
    "                n[i] = m[i][len(a)]\n",
    "\n",
    "                for j in range(i+1,len(a)):\n",
    "                    n[i] = n[i] - m[i][j]*n[j]\n",
    "\n",
    "                n[i] = n[i]/m[i][i]\n",
    "            return n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82e7af2",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3684572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shorthand reference:\n",
    "snp = SNumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864ec0c0",
   "metadata": {},
   "source": [
    "#### 1) SNumPy.ones(Int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aadea17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(snp.ones(5))\n",
    "print(snp.ones(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fb275",
   "metadata": {},
   "source": [
    "#### 2) SNumPy.zeros(Int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb28bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(snp.zeros(3))\n",
    "print(snp.zeros(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f757ae",
   "metadata": {},
   "source": [
    "#### 3) SNumPy.reshape(array, row, column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574edf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11]]\n",
      "[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]]\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n"
     ]
    }
   ],
   "source": [
    "arr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "print(snp.reshape(arr, 6, 2))\n",
    "print(snp.reshape(arr, 3, 4))\n",
    "print(snp.reshape(arr, 4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dbbf95",
   "metadata": {},
   "source": [
    "#### 4) SNumPy.shape(array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54cd133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(3, 3)\n",
      "(3, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "arr2 = [[0, 1, 2, 3], [3, 4, 5, 6], [6, 7, 8, 9]]\n",
    "arr3 = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
    "print(snp.shape(arr2))\n",
    "print(snp.shape(arr3))\n",
    "#Test with vector:\n",
    "v = [2, 4, 6]\n",
    "print(snp.shape(v))\n",
    "#Test with single value:\n",
    "print(snp.shape(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbf646",
   "metadata": {},
   "source": [
    "#### 5) SNumPy.append(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e03afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x4 and 3x3:\n",
      "[[0, 1, 2, 3], [3, 4, 5, 6], [6, 7, 8, 9]]\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
      "[[0, 1, 2, 3, 0, 1, 2], [3, 4, 5, 6, 3, 4, 5], [6, 7, 8, 9, 6, 7, 8]]\n",
      "3x3 and 3x3:\n",
      "[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
      "[[5, 1, 3], [2, 5, 5], [8, 7, 2]]\n",
      "[[0, 1, 2, 5, 1, 3], [3, 4, 5, 2, 5, 5], [6, 7, 8, 8, 7, 2]]\n",
      "1x3 and 1x3:\n",
      "[[2, 4, 6, 3, 5, 8]]\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x4 and 3x3:\n",
    "print(\"3x4 and 3x3:\")\n",
    "print(arr2)\n",
    "print(arr3)\n",
    "print(snp.append(arr2, arr3))\n",
    "\n",
    "#Test with 3x3 and 3x3:\n",
    "print(\"3x3 and 3x3:\")\n",
    "arr4 = [[5, 1, 3], [2, 5, 5], [8, 7, 2]]\n",
    "print(arr3)\n",
    "print(arr4)\n",
    "print(snp.append(arr3, arr4))\n",
    "\n",
    "#Test with vector:\n",
    "v2 = [3, 5, 8]\n",
    "print(\"1x3 and 1x3:\")\n",
    "print(snp.append(v, v2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a70f3",
   "metadata": {},
   "source": [
    "#### 6) SNumPy.get(array, row, column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf57b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 1, 3], [2, 5, 5], [8, 7, 2]]\n",
      "[8]\n"
     ]
    }
   ],
   "source": [
    "print(arr4)\n",
    "#The indexing starts from 1\n",
    "print(snp.get(arr4, 3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a5a82",
   "metadata": {},
   "source": [
    "#### 7) SNumPy.add(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f9e862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5, 5, 14], [2, 9, 14], [5, 10, 10]]\n",
      "[[5], [9], [14]]\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x3 and 3x3:\n",
    "print(snp.add(arr3, arr4))\n",
    "\n",
    "#Test with 1x3 vectors:\n",
    "print(snp.add(v,v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a378bc2",
   "metadata": {},
   "source": [
    "#### 8) SNumPy.subtract(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a1d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5, 1, -2], [0, -1, 0], [-1, 0, 6]]\n",
      "[[1], [1], [2]]\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x3 and 3x3:\n",
    "print(snp.subtract(arr3, arr4))\n",
    "\n",
    "#Test with 1x3 vectors:\n",
    "print(snp.subtract(v2,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f655f8a2",
   "metadata": {},
   "source": [
    "#### 9) SNumPy.dotproduct(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12413ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18, 19, 9], [63, 58, 39], [108, 97, 69]]\n",
      "[[33, 31, 4], [102, 91, 19], [171, 151, 34]]\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x3 and 3x3:\n",
    "print(snp.dotproduct(arr3, arr4))\n",
    "\n",
    "#Test with 3x4 and 4x3:\n",
    "arr5 = [[8, 2, 3], [2, 7, 1], [8, 9, 0], [5, 2, 1]]\n",
    "print(snp.dotproduct(arr2, arr5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63c9942",
   "metadata": {},
   "source": [
    "#### 10) SNumPy.gaussian(a, b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a1ee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-15.0, 8.0, 2.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,3,-2], [3,5,6],[2,4,3]]\n",
    "b = [5,7,8]\n",
    "snp.gaussian(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78994b7",
   "metadata": {},
   "source": [
    "## Exception Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182a42b",
   "metadata": {},
   "source": [
    "#### 1) SNumPy.ones(Int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29646cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has to be integer!\n"
     ]
    }
   ],
   "source": [
    "print(snp.ones(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15025fa",
   "metadata": {},
   "source": [
    "#### 2) SNumPy.zeros(Int):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0fc7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input has to be integer!\n"
     ]
    }
   ],
   "source": [
    "print(snp.zeros(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde9fc8e",
   "metadata": {},
   "source": [
    "#### 3) SNumPy.reshape(array, row, column):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b295c9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row and column must be integers!\n",
      "Cannot reshape array of size 12 into shape (3,5).\n"
     ]
    }
   ],
   "source": [
    "print(snp.reshape(arr, 4, \"test\"))\n",
    "print(snp.reshape(arr, 3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d811e",
   "metadata": {},
   "source": [
    "#### 5) SNumPy.append(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e595fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3x4 and 4x3:\n",
      "The given arrays do not have the same number of rows.\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x4 and 4x3:\n",
    "arr5 = [[8, 2, 3], [2, 7, 1], [8, 9, 0], [5, 2, 1]]\n",
    "print(\"3x4 and 4x3:\")\n",
    "print(snp.append(arr2, arr5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78054a9c",
   "metadata": {},
   "source": [
    "#### 7) SNumPy.add(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe16c1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the given arrays do not match.\n",
      "The shapes of the given arrays do not match.\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x4 and 3x3:\n",
    "print(snp.add(arr2, arr3))\n",
    "#Test with 3x4 and 4x3:\n",
    "print(snp.add(arr2, arr5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135ec28b",
   "metadata": {},
   "source": [
    "#### 8) SNumPy.subtract(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f9fd8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shapes of the given arrays do not match.\n",
      "The shapes of the given arrays do not match.\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x4 and 3x3:\n",
    "print(snp.subtract(arr2, arr3))\n",
    "#Test with 3x4 and 4x3:\n",
    "print(snp.subtract(arr2, arr5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a95905",
   "metadata": {},
   "source": [
    "#### 9) SNumPy.dotproduct(array1, array2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2037f29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of columns in array1 does not equal the number of rows in array2.\n"
     ]
    }
   ],
   "source": [
    "#Test with 3x4 and 3x3:\n",
    "print(snp.dotproduct(arr2, arr3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cd0c8c",
   "metadata": {},
   "source": [
    "#### 10) SNumPy.gaussian(a, b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0822cc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same amount of equations must be given. E.g. if equations are k*x_0 + l*x_1 = a, m*x_0 + n*x_1 = b, input arrays must be [[k,l],[m,n]] and [a,b]\n",
      "All equations must contain the same number of unknowns. E.g. if equations are k*x_0 + l*x_1 = a, m*x_0 + n*x_1 = b, input arrays must be [[k,l],[m,n]] and [a,b]\n"
     ]
    }
   ],
   "source": [
    "#Test with\n",
    "a = [[1,3,-2], [3,5,6],[2,4,3]]\n",
    "b = [5,7,8,9]\n",
    "print(snp.gaussian(a,b))\n",
    "c = [[3,-2], [3,5,6],[2,4,3]]\n",
    "d = [5,7,8]\n",
    "print(snp.gaussian(c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11737d15",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ad965",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ec98d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9c5a6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0282cb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating the necessary matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d9888d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming's Generetor Matrix \n",
    "G=np.array([[1,1,0,1],\n",
    "            [1,0,1,1], \n",
    "            [1,0,0,0],\n",
    "            [0,1,1,1],\n",
    "            [0,1,0,0],\n",
    "            [0,0,1,0],\n",
    "            [0,0,0,1]])\n",
    "\n",
    "#Check array \n",
    "H= np.array([[1,0,1,0,1,0,1],\n",
    "             [0,1,1,0,0,1,1],\n",
    "             [0,0,0,1,1,1,1]])\n",
    "#decoder \n",
    "R=np.array([[0,0,1,0,0,0,0],\n",
    "            [0,0,0,0,1,0,0],\n",
    "            [0,0,0,0,0,1,0],\n",
    "            [0,0,0,0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca14293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5846b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hamming(array):\n",
    "    try:\n",
    "        if ((array==0) | (array==1)).all():\n",
    "            encoded = np.matmul(G,array) % 2\n",
    "            print(\"The 7 bit code is:\")\n",
    "            print(encoded)\n",
    "\n",
    "            print(\"Parity test:\")\n",
    "            parity = np.matmul(H,encoded) % 2\n",
    "            print(parity)\n",
    "            if sum(abs(parity)) == 0:\n",
    "                print(\"Parity check passed\")\n",
    "\n",
    "                decoded = np.matmul(R, encoded)\n",
    "                print(\"The decoded vector:\")\n",
    "                print(decoded)\n",
    "                if sum(array == decoded) == 4:\n",
    "                    return \"All calculations are correct.\"\n",
    "                else:\n",
    "                    return \"Errors in calculation!\"\n",
    "\n",
    "            else:\n",
    "                return \"Parity check not passed!\"\n",
    "        else:\n",
    "            return \"Input vector is not binary!\"\n",
    "        \n",
    "    except ValueError:\n",
    "        return \"The vector has to be 4 bits!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a3ad9",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bedbda44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7 bit code is:\n",
      "[0 1 1 0 0 1 1]\n",
      "Parity test:\n",
      "[0 0 0]\n",
      "Parity check passed\n",
      "The decoded vector:\n",
      "[1 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All calculations are correct.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test cases\n",
    "arr1 = np.array([1,0,1,1])\n",
    "Hamming(arr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3bfc4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7 bit code is:\n",
      "[1 1 0 1 0 0 1]\n",
      "Parity test:\n",
      "[0 0 0]\n",
      "Parity check passed\n",
      "The decoded vector:\n",
      "[0 0 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All calculations are correct.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2 = np.array([0,0,0,1])\n",
    "Hamming(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7de67e77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7 bit code is:\n",
      "[1 0 1 1 0 1 0]\n",
      "Parity test:\n",
      "[0 0 0]\n",
      "Parity check passed\n",
      "The decoded vector:\n",
      "[1 0 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All calculations are correct.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3 = np.array([1,0,1,0])\n",
    "Hamming(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "549833af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 7 bit code is:\n",
      "[1 1 0 0 1 1 0]\n",
      "Parity test:\n",
      "[0 0 0]\n",
      "Parity check passed\n",
      "The decoded vector:\n",
      "[0 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All calculations are correct.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr4 = np.array([0,1,1,0])\n",
    "Hamming(arr4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23bfb56",
   "metadata": {},
   "source": [
    "## Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9fa637e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Input vector is not binary!'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr5 = np.array([2,0,1,2])\n",
    "Hamming(arr5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3dca2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The vector has to be 4 bits!'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr6 = np.array([0,0,1])\n",
    "Hamming(arr6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b923de1",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7827e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's create the text corpus, as well as the search string:\n",
    "# The strings of the text corpus must be given in a list of lists, with their titles:\n",
    "# (Generated by https://randomwordgenerator.com/paragraph.php)\n",
    "input_corpus = [\n",
    "    [\"String 1\", \"The alarm went off at exactly 6:00 AM as it had every morning for the past five years\"],\n",
    "    \n",
    "    [\"String 2\", \"Barbara began her morning and was ready to eat breakfast by 7:00 AM\"],\n",
    "    \n",
    "    [\"String 3\", \"The day appeared to be as normal as any other, but that was about to change\"],\n",
    "    \n",
    "    [\"String 4\", \"In fact, it was going to change at exactly 7:23 AM\"],\n",
    "    \n",
    "    [\"String 5\", \"It was supposed to be a dream vacation\"],\n",
    "    \n",
    "    [\"String 6\", \"They had planned it over a year in advance so that it would be perfect in every way\"],\n",
    "    \n",
    "    [\"String 7\", \"It had been what they had been looking forward to through all the turmoil and negativity around them\"],\n",
    "    \n",
    "    [\"String 8\", \"It had been the light at the end of both their tunnels\"]    \n",
    "]\n",
    "# Next, the search string:\n",
    "input_search = \"Now that the dream vacation was only a week away, the virus had stopped all air travel\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1bae7e",
   "metadata": {},
   "source": [
    "## We provide multiple ways to analyze text similarities.\n",
    "### The first one looks at the Damerauâ€“Levenshtein distance between two strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcd83bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dam_Lev_dist(str1, str2):\n",
    "    # The function uses https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "    # We need to make sure that the inputs are strings:\n",
    "    if type(str1) != str:\n",
    "        print(\"Input should be string. It has been converted to string.\")\n",
    "        str1 = str(str1)\n",
    "    if type(str2) != str:\n",
    "        print(\"Input should be string. It has been converted to string.\")\n",
    "        str2 = str(str2)\n",
    "    # The script goes through the two strings to look at the minimum number of operations in steps\n",
    "    oneago = None\n",
    "    thisrow = list(range(1, len(str2) + 1)) + [0]\n",
    "    for x in range(len(str1)):\n",
    "        twoago, oneago, thisrow = oneago, thisrow, [0] * len(str2) + [x + 1]\n",
    "        for y in range(len(str2)):\n",
    "            # Removing a character\n",
    "            delcost = oneago[y] + 1\n",
    "            # Adding a character\n",
    "            addcost = thisrow[y - 1] + 1\n",
    "            # Substituting a character\n",
    "            subcost = oneago[y - 1] + (str1[x] != str2[y])\n",
    "            thisrow[y] = min(delcost, addcost, subcost)\n",
    "            # Switching two characters\n",
    "            if (x > 0 and y > 0 and str1[x] == str2[y - 1]\n",
    "                and str1[x-1] == str2[y] and str1[x] != str2[y]):\n",
    "                thisrow[y] = min(thisrow[y], twoago[y - 2] + 1)\n",
    "    return thisrow[len(str2) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807bfc1c",
   "metadata": {},
   "source": [
    "#### Defining the ranking function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a4d2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dam_Lev_ranking(corpus, search_string):\n",
    "    # Creating two lists of corpus: titles and strings:\n",
    "    corpus_titles = [x[0] for x in corpus]\n",
    "    corpus_string = [x[1] for x in corpus]\n",
    "    # Checking that the inputs are strings:\n",
    "    for i in range(len(corpus_string)):\n",
    "        if type(corpus_string[i]) != str:\n",
    "            print(\"User inputs should be string. We converted the values that aren't.\")\n",
    "            corpus_string[i] = str(corpus_string[i])\n",
    "    if type(search_string) != str:\n",
    "        print(\"Search string should be string. We converted it to string.\")\n",
    "        search_string = str(search_string)\n",
    "    # Calculating the distances based on the above function:\n",
    "    output_ranks = []\n",
    "    for i in range(len(corpus_string)):\n",
    "        output_ranks.append(Dam_Lev_dist(corpus_string[i],search_string))\n",
    "    # Determining the ranks based on the distances\n",
    "    final_ranking = []\n",
    "    place = 1\n",
    "    tie_breaker = 0\n",
    "    k = 0\n",
    "    # Creating output titles (the first 50 characters of the strigns only)\n",
    "    output_titles = []\n",
    "    for i in range(len(corpus_string)):\n",
    "        if len(corpus_string[i]) > 50:\n",
    "            output_titles.append((corpus_string[i][:50] + \"...\"))\n",
    "        else:\n",
    "            output_titles.append(corpus_string[i])\n",
    "    while k <= max(output_ranks):\n",
    "        for i in range(len(output_ranks)):\n",
    "            if output_ranks[i] == k:\n",
    "                if output_ranks.count(k) > tie_breaker:\n",
    "                    # Assingning the ranks\n",
    "                    final_ranking.append(\"Rank #\" + str(place) + \" (\" + str(output_ranks[i]) + \n",
    "                                         \" distance): \" + str(corpus_titles[i]) + \": \" + str(output_titles[i]))\n",
    "                    tie_breaker += 1\n",
    "                if tie_breaker > 0 and tie_breaker == output_ranks.count(k):\n",
    "                    place += 1\n",
    "        tie_breaker = 0\n",
    "        k += 1\n",
    "    return final_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5187dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (60 distance): String 8: It had been the light at the end of both their tun...',\n",
       " 'Rank #2 (61 distance): String 3: The day appeared to be as normal as any other, but...',\n",
       " 'Rank #3 (67 distance): String 2: Barbara began her morning and was ready to eat bre...',\n",
       " 'Rank #3 (67 distance): String 4: In fact, it was going to change at exactly 7:23 AM',\n",
       " 'Rank #4 (68 distance): String 1: The alarm went off at exactly 6:00 AM as it had ev...',\n",
       " 'Rank #4 (68 distance): String 5: It was supposed to be a dream vacation',\n",
       " 'Rank #4 (68 distance): String 6: They had planned it over a year in advance so that...',\n",
       " 'Rank #5 (73 distance): String 7: It had been what they had been looking forward to ...']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dam_Lev_ranking(input_corpus, input_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90692858",
   "metadata": {},
   "source": [
    "#### The above solution works best with texts of similar length, as the difference in length increases the distance, regardless of the other similarities of the two strings. The solution is also not concerned with the words individually.\n",
    "\n",
    "#### The following methods will instead take a look at the words' frequencies in the total text corpus\n",
    "#### and calculate the distance based on the number of similar words and their frequencies.\n",
    "##### We will show two methods of calculating distance: dot products and Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db52c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use logarithms in the function\n",
    "import math\n",
    "# We will use dot products\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86090392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_distance_matrix(corpus, search_string):\n",
    "    # We use a Term Frequency / Inverse Document Frequency model based on\n",
    "    # https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "    # Creating two lists of corpus: titles and strings:\n",
    "    corpus_titles_wdm = [x[0] for x in corpus]\n",
    "    corpus_string_wdm = [x[1] for x in corpus]\n",
    "    # Checking that the inputs are strings:\n",
    "    for i in range(len(corpus_string_wdm)):\n",
    "        if type(corpus_string_wdm[i]) != str:\n",
    "            print(\"User inputs should be string. We converted the values that aren't.\")\n",
    "            corpus_string_wdm[i] = str(corpus_string_wdm[i])\n",
    "    if type(search_string) != str:\n",
    "        print(\"Search string should be string. We converted it to string.\")\n",
    "        search_string = str(search_string)\n",
    "    # Removing all characters from the strings that are not letters, numbers, or spaces:\n",
    "    whitelist = set('abcdefghijklmnopqrstuvwxyz ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789')\n",
    "    search_string = ''.join(filter(whitelist.__contains__, search_string))\n",
    "    # Turning uppercase characters into lower case:\n",
    "    search_string = search_string.lower()\n",
    "    for i in range(len(corpus_string_wdm)):\n",
    "        corpus_string_wdm[i] = ''.join(filter(whitelist.__contains__, corpus_string_wdm[i]))\n",
    "        corpus_string_wdm[i] = corpus_string_wdm[i].lower()\n",
    "    # Separating all words in all strings:\n",
    "    search_string_separated = search_string.split()\n",
    "    corpus_separated = [None] * len(corpus_string_wdm)\n",
    "    for i in range(len(corpus_string_wdm)):\n",
    "        corpus_separated[i] = corpus_string_wdm[i].split()\n",
    "    # We use an inverse document frequency to weight the words\n",
    "    # First, we create a dictionary of each word in the strings:\n",
    "    dictionary = []\n",
    "    for i in range(len(search_string_separated)):\n",
    "        dictionary.append(search_string_separated[i])\n",
    "    for i in range(len(corpus_separated)):\n",
    "        for j in range(len(corpus_separated[i])):\n",
    "            dictionary.append(corpus_separated[i][j])\n",
    "    dictionary = list(dict.fromkeys(dictionary))\n",
    "    # We calculate this by looking at the number of strings a word occurs in:\n",
    "    N = len(corpus_string_wdm) + 1\n",
    "    dictionary_weights = [dictionary,[None] * len(dictionary)]\n",
    "    # Getting each word's weight:\n",
    "    for i in range(len(dictionary)):\n",
    "        # The number of documents the word occurs in:\n",
    "        C = 0\n",
    "        if dictionary[i] in search_string_separated:\n",
    "            C += 1\n",
    "        for j in range(len(corpus_separated)):\n",
    "            if dictionary[i] in corpus_separated[j]:\n",
    "                C += 1\n",
    "        dictionary_weights[1][i] = math.log(N / C)\n",
    "    # Creating output titles (the first 50 characters of the strigns only)\n",
    "    output_titles = []\n",
    "    for i in range(len(corpus_string_wdm)):\n",
    "        if len(corpus_string_wdm[i]) > 50:\n",
    "            output_titles.append((str(corpus_titles_wdm[i]) + \": \" + str(corpus_string_wdm[i][:50] + \"...\")))\n",
    "        else:\n",
    "            output_titles.append(str(corpus_titles_wdm[i]) + \": \" + corpus_string_wdm[i])\n",
    "    if len(search_string) > 50:\n",
    "        search_string_title = search_string[:50] + \"...\"\n",
    "    else:\n",
    "        search_string_title = search_string\n",
    "    # Next, we need to create vectors for each string based on the dictionary's weights.\n",
    "    # We will have an output matrix, with the strings in one dimension and the word values in another.\n",
    "    matrix = [[0 for i in range(len(corpus_string_wdm)+1)] for j in range(len(dictionary)+1)]\n",
    "    matrix[0][0] = search_string_title\n",
    "    for i in range(len(corpus_string_wdm)):\n",
    "        matrix[0][i+1] = output_titles[i]\n",
    "    # Filling the matrix with the word weight values:\n",
    "    for i in range(len(dictionary)):\n",
    "        matrix[i+1][0] = (search_string_separated.count(dictionary_weights[0][i]) * \n",
    "                          dictionary_weights[1][i])\n",
    "    for i in range(1,len(corpus_string_wdm)+1):\n",
    "        for j in range(len(dictionary)):\n",
    "            matrix[j+1][i] = (corpus_separated[i-1].count(dictionary_weights[0][j]) *\n",
    "                              dictionary_weights[1][j])\n",
    "    # This matrix is used in the other functions later on to calculate the distances between strings\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "78408aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculatin distances from dot products\n",
    "def dot_product_matrix(corpus, search_string):\n",
    "    # Creating two lists of corpus: titles and strings:\n",
    "    corpus_titles = [x[0] for x in corpus]\n",
    "    corpus_string = [x[1] for x in corpus]\n",
    "    # Loading the word_distance_matrix function:\n",
    "    word_distances = word_distance_matrix(corpus, search_string)\n",
    "    # Calculating the output distances:\n",
    "    dot_product_distances = []\n",
    "    for i in range(len(corpus_string)):\n",
    "        dot_product_distances.append(np.dot([j[0] for j in word_distances][1:],\n",
    "                                            [j[i+1] for j in word_distances][1:]) /\n",
    "                                    len(corpus_string[i]) * 100)\n",
    "    # We calculate it twice, once for the rankings and once for the output:\n",
    "    final_ranking_distances = []\n",
    "    for i in range(len(corpus_string)):\n",
    "        final_ranking_distances.append(np.dot([j[0] for j in word_distances][1:],\n",
    "                                            [j[i+1] for j in word_distances][1:]) /\n",
    "                                      len(corpus_string[i]) * 100)\n",
    "    # We now have our dot product results. Higher values mean more similarity.\n",
    "    final_ranking = ([word_distances[0][1:]] +\n",
    "                     [final_ranking_distances])\n",
    "    # Determining the ranks based on the distances\n",
    "    total_dist = sum(dot_product_distances)\n",
    "    place = 1\n",
    "    place_vector = [None] * len(corpus_string)\n",
    "    while max(dot_product_distances) > 0:\n",
    "        for i in range(len(corpus_string)):\n",
    "            if dot_product_distances[i] == max(dot_product_distances):\n",
    "                place_vector[i] = place\n",
    "                for j in range(len(corpus_string)):\n",
    "                    if dot_product_distances[i] == dot_product_distances[j] and i != j:\n",
    "                        place_vector[j] = place\n",
    "                        dot_product_distances[j] -= total_dist\n",
    "                        if max(dot_product_distances) < 0:\n",
    "                            break\n",
    "                dot_product_distances[i] -= total_dist\n",
    "                if max(dot_product_distances) < 0:\n",
    "                    break\n",
    "                place += 1\n",
    "    final_ranking.append(place_vector)\n",
    "    final_ranking_ordered = []\n",
    "    k = 1\n",
    "    while k <= place:\n",
    "        for i in range(len(place_vector)):\n",
    "            if k == place_vector[i]:\n",
    "                final_ranking_ordered.append([str(final_ranking[0][i])] +\n",
    "                                     [str(final_ranking[1][i])] +\n",
    "                                     [str(final_ranking[2][i])])\n",
    "        k += 1        \n",
    "    final_output = []\n",
    "    for i in range(len(final_ranking_ordered)):\n",
    "        final_output.append(\"Rank #\" + final_ranking_ordered[i][2] + \" (\" +\n",
    "                            str(final_ranking_ordered[i][1])[:7] + \n",
    "                            \" distance): \" + str(final_ranking_ordered[i][0]))\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6439ebdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (15.9919 distance): String 5: it was supposed to be a dream vacation',\n",
       " 'Rank #2 (3.64422 distance): String 7: it had been what they had been looking forward to ...',\n",
       " 'Rank #3 (3.32456 distance): String 6: they had planned it over a year in advance so that...',\n",
       " 'Rank #4 (3.19901 distance): String 8: it had been the light at the end of both their tun...',\n",
       " 'Rank #5 (2.99123 distance): String 3: the day appeared to be as normal as any other but ...',\n",
       " 'Rank #6 (2.03231 distance): String 1: the alarm went off at exactly 600 am as it had eve...',\n",
       " 'Rank #7 (0.69098 distance): String 4: in fact it was going to change at exactly 723 am',\n",
       " 'Rank #8 (0.51566 distance): String 2: barbara began her morning and was ready to eat bre...']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_matrix(input_corpus, input_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5a063",
   "metadata": {},
   "source": [
    "#### From the same matrix we can also calculate the Euclidean distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05c04817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the following package for Euclidean distances:\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de292a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Euclidean_distance(corpus, search_string):\n",
    "    # Creating two lists of corpus: titles and strings:\n",
    "    corpus_titles = [x[0] for x in corpus]\n",
    "    corpus_string = [x[1] for x in corpus]\n",
    "    # Loading the word_distance_matrix function:\n",
    "    word_distances = word_distance_matrix(corpus, search_string)\n",
    "    dot_product_distances = []\n",
    "    for i in range(len(corpus)):\n",
    "        dot_product_distances.append(distance.euclidean(([j[0] for j in word_distances][1:]),\n",
    "                   [j[i+1] for j in word_distances][1:]))\n",
    "    # We calculate it twice, once for the rankings and once for the output:\n",
    "    final_ranking_distances = []\n",
    "    for i in range(len(corpus)):\n",
    "        final_ranking_distances.append(distance.euclidean(([j[0] for j in word_distances][1:]),\n",
    "                   [j[i+1] for j in word_distances][1:]))\n",
    "    # We now have our dot product results. Higher values mean more similarity.\n",
    "    final_ranking = ([word_distances[0][1:]] +\n",
    "                     [final_ranking_distances])\n",
    "    # Determining the ranks based on the distances\n",
    "    total_dist = 10000\n",
    "    place = 1\n",
    "    place_vector = [None] * len(corpus)\n",
    "    while min(dot_product_distances) < total_dist:\n",
    "        for i in range(len(corpus)):\n",
    "            if dot_product_distances[i] == min(dot_product_distances):\n",
    "                place_vector[i] = place\n",
    "                for j in range(len(corpus)):\n",
    "                    if dot_product_distances[i] == dot_product_distances[j] and i != j:\n",
    "                        place_vector[j] = place\n",
    "                        dot_product_distances[j] += total_dist\n",
    "                        if min(dot_product_distances) > total_dist:\n",
    "                            break\n",
    "                dot_product_distances[i] += total_dist\n",
    "                if min(dot_product_distances) > total_dist:\n",
    "                    break\n",
    "                place += 1\n",
    "    final_ranking.append(place_vector)\n",
    "    final_ranking_ordered = []\n",
    "    k = 1\n",
    "    while k <= place:\n",
    "        for i in range(len(place_vector)):\n",
    "            if k == place_vector[i]:\n",
    "                final_ranking_ordered.append([str(final_ranking[0][i])] +\n",
    "                                     [str(final_ranking[1][i])] +\n",
    "                                     [str(final_ranking[2][i])])\n",
    "        k += 1        \n",
    "    final_output = []\n",
    "    for i in range(len(final_ranking_ordered)):\n",
    "        final_output.append(\"Rank #\" + final_ranking_ordered[i][2] + \" (\" +\n",
    "                            str(final_ranking_ordered[i][1])[:7] + \n",
    "                            \" distance): \" + str(final_ranking_ordered[i][0]))\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bee7bf5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (7.09673 distance): String 5: it was supposed to be a dream vacation',\n",
       " 'Rank #2 (8.58745 distance): String 4: in fact it was going to change at exactly 723 am',\n",
       " 'Rank #3 (8.98715 distance): String 8: it had been the light at the end of both their tun...',\n",
       " 'Rank #4 (9.70823 distance): String 2: barbara began her morning and was ready to eat bre...',\n",
       " 'Rank #5 (9.74688 distance): String 3: the day appeared to be as normal as any other but ...',\n",
       " 'Rank #6 (9.92059 distance): String 1: the alarm went off at exactly 600 am as it had eve...',\n",
       " 'Rank #7 (9.96508 distance): String 7: it had been what they had been looking forward to ...',\n",
       " 'Rank #8 (10.0596 distance): String 6: they had planned it over a year in advance so that...']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distance(input_corpus, input_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b4c74",
   "metadata": {},
   "source": [
    "#### Now let's see the three computational methods on 10 poems (3 by Edgar Allan Poe, 3 by Walt Whitman, 3 by Oscar Fingal O'Flahertie Wills Wilde, and the search string by William Shakespeare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e82a2784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the strings:\n",
    "with open('C:/CBS/Foundations/final/poems/Poe_Alone.txt', 'r') as file:\n",
    "    Poe_Alone = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Poe_Annabel Lee.txt', 'r') as file:\n",
    "    Poe_Annabel_Lee = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Poe_The Raven.txt', 'r') as file:\n",
    "    Poe_The_Raven = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Shakespeare_The Phoenix and the Turtle.txt', 'r') as file:\n",
    "    Shakespeare_The_Phoenix_and_the_Turtle = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Whitman_I Hear America Singing.txt', 'r') as file:\n",
    "    Whitman_I_Hear_America_Singing = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Whitman_I Sing The Body Electric.txt', 'r') as file:\n",
    "    Whitman_I_Sing_The_Body_Electric = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Whitman_When Lilacs Last in the Dooryard Bloomd.txt', 'r') as file:\n",
    "    Whitman_When_Lilacs_Last_in_the_Dooryard_Bloomd = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Wilde_Requiescat.txt', 'r') as file:\n",
    "    Wilde_Requiescat = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Wilde_The Burden Of Itys.txt', 'r') as file:\n",
    "    Wilde_The_Burden_Of_Itys = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/poems/Wilde_The Garden of Eros.txt', 'r') as file:\n",
    "    Wilde_The_Garden_of_Eros = file.read().replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1115539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem_corpus = [[\"Poe_Alone.txt\", Poe_Alone], \n",
    "               [\"Poe_Annabel Lee.txt\", Poe_Annabel_Lee], \n",
    "               [\"Poe_The Raven.txt\", Poe_The_Raven], \n",
    "               [\"Whitman_I Hear America Singing.txt\", Whitman_I_Hear_America_Singing],\n",
    "               [\"Whitman_I Sing The Body Electric.txt\", Whitman_I_Sing_The_Body_Electric], \n",
    "               [\"Whitman_When Lilacs Last in the Dooryard Bloomd.txt\", Whitman_When_Lilacs_Last_in_the_Dooryard_Bloomd],\n",
    "               [\"Wilde_Requiescat.txt\", Wilde_Requiescat], \n",
    "               [\"Wilde_The Burden Of Itys.txt\", Wilde_The_Burden_Of_Itys], \n",
    "               [\"Wilde_The Garden of Eros.txt\", Wilde_The_Garden_of_Eros]]\n",
    "poem_search = Shakespeare_The_Phoenix_and_the_Turtle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "875976e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (1449 distance): Poe_Annabel Lee.txt: It was many and many a year ago, In a kingdom by t...',\n",
       " 'Rank #2 (1544 distance): Whitman_I Hear America Singing.txt: I hear America singing, the varied carols I hear; ...',\n",
       " 'Rank #3 (1605 distance): Poe_Alone.txt: From childhoodÃ¢â‚¬â„¢s hour I have not been As others ...',\n",
       " 'Rank #4 (1712 distance): Wilde_Requiescat.txt: Tread lightly, she is near Under the snow, Speak g...',\n",
       " 'Rank #5 (4926 distance): Poe_The Raven.txt: Once upon a midnight dreary, while I pondered, wea...',\n",
       " 'Rank #6 (10438 distance): Whitman_When Lilacs Last in the Dooryard Bloomd.txt: 1 When lilacs last in the dooryard bloomÃ¢â‚¬â„¢d, And ...',\n",
       " 'Rank #7 (10663 distance): Wilde_The Garden of Eros.txt: It is full summer now, the heart of June; Not yet ...',\n",
       " 'Rank #8 (10836 distance): Whitman_I Sing The Body Electric.txt: I sing the Body electric; The armies of those I lo...',\n",
       " 'Rank #9 (13978 distance): Wilde_The Burden Of Itys.txt: This English Thames is holier far than Rome, Those...']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Damerauâ€“Levenshtein distances:\n",
    "Dam_Lev_ranking(poem_corpus, poem_search)\n",
    "# (Takes a while to load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6dce1311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99581866]\n",
      " [0.99581866 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# To see the issue with the Damerau-Levenshtein distance in such long documents,\n",
    "# let's see how the distances correlate with the string lengths\n",
    "distances = [1605, 1449, 4926, 1544, 10836, 10438, 1712, 13978, 10663]\n",
    "string_lengths = []\n",
    "poem_corpus_strings = [x[1] for x in poem_corpus]\n",
    "for i in range(len(distances)):\n",
    "    string_lengths.append(len(poem_corpus_strings[i]))\n",
    "print(np.corrcoef(distances, string_lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b5ea46",
   "metadata": {},
   "source": [
    "#### As we can see, there is a very high correlation between a strings' distances and the string's\n",
    "#### relative length compared to the search string. This makes the algorithm useless for such strings,\n",
    "#### which vary largely in lenght. Now, let's see the distances from the dot product method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88a4d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (3.22161 distance): Poe_Annabel Lee.txt: it was many and many a year ago in a kingdom by th...',\n",
       " 'Rank #2 (2.50333 distance): Wilde_Requiescat.txt: tread lightly she is near under the snow speak gen...',\n",
       " 'Rank #3 (1.69688 distance): Wilde_The Garden of Eros.txt: it is full summer now the heart of june not yet th...',\n",
       " 'Rank #4 (1.64635 distance): Poe_Alone.txt: from childhoods hour i have not been as others wer...',\n",
       " 'Rank #5 (1.44305 distance): Whitman_I Sing The Body Electric.txt: i sing the body electric the armies of those i lov...',\n",
       " 'Rank #6 (1.42301 distance): Wilde_The Burden Of Itys.txt: this english thames is holier far than rome those ...',\n",
       " 'Rank #7 (1.34545 distance): Whitman_When Lilacs Last in the Dooryard Bloomd.txt: 1 when lilacs last in the dooryard bloomd and the ...',\n",
       " 'Rank #8 (1.28547 distance): Poe_The Raven.txt: once upon a midnight dreary while i pondered weak ...',\n",
       " 'Rank #9 (0.80509 distance): Whitman_I Hear America Singing.txt: i hear america singing the varied carols i hear th...']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_matrix(poem_corpus, poem_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcfd7162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.36423634]\n",
      " [-0.36423634  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Now let's see if these distances correlate with string lengths:\n",
    "dot_product_distances = [1.64635, 3.22161, 1.28547, 0.80509, 1.44305, 1.34545, 2.50333, 1.42301, 1.69688]\n",
    "print(np.corrcoef(dot_product_distances, string_lengths))\n",
    "# They are not correlated, because we already accounted for string lengths in the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b670b",
   "metadata": {},
   "source": [
    "#### And finally let's see the Euclidean distance ranks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eb9102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (32.4426 distance): Wilde_Requiescat.txt: tread lightly she is near under the snow speak gen...',\n",
       " 'Rank #2 (33.4728 distance): Poe_Alone.txt: from childhoods hour i have not been as others wer...',\n",
       " 'Rank #3 (42.5969 distance): Whitman_I Hear America Singing.txt: i hear america singing the varied carols i hear th...',\n",
       " 'Rank #4 (43.4422 distance): Poe_Annabel Lee.txt: it was many and many a year ago in a kingdom by th...',\n",
       " 'Rank #5 (88.7217 distance): Wilde_The Garden of Eros.txt: it is full summer now the heart of june not yet th...',\n",
       " 'Rank #6 (89.1769 distance): Poe_The Raven.txt: once upon a midnight dreary while i pondered weak ...',\n",
       " 'Rank #7 (101.469 distance): Whitman_When Lilacs Last in the Dooryard Bloomd.txt: 1 when lilacs last in the dooryard bloomd and the ...',\n",
       " 'Rank #8 (103.808 distance): Whitman_I Sing The Body Electric.txt: i sing the body electric the armies of those i lov...',\n",
       " 'Rank #9 (107.160 distance): Wilde_The Burden Of Itys.txt: this english thames is holier far than rome those ...']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Euclidean_distance(poem_corpus, poem_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b10e2bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.95721818]\n",
      " [0.95721818 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Once again, let's see if these results depend on the strings' lengths:\n",
    "Euclidean_distances = [33.4728, 43.4422, 88.1769, 42.5969, 103.808, 101.469, 32.4426, 107.160, 88.7217]\n",
    "print(np.corrcoef(Euclidean_distances, string_lengths))\n",
    "# There is a large correlation between the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199009d3",
   "metadata": {},
   "source": [
    "### Finally, we'll take a look at a number of strings which do not vary as much in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0056f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the strings:\n",
    "with open('C:/CBS/Foundations/final/same_length/string1.txt', 'r') as file:\n",
    "    string1 = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/same_length/string2.txt', 'r') as file:\n",
    "    string2 = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/same_length/string3.txt', 'r') as file:\n",
    "    string3 = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/same_length/string4.txt', 'r') as file:\n",
    "    string4 = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/same_length/string5.txt', 'r') as file:\n",
    "    string5 = file.read().replace('\\n', ' ')\n",
    "with open('C:/CBS/Foundations/final/same_length/same_length_search_string.txt', 'r') as file:\n",
    "    same_length_search_string = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f44bf7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_length_corpus = [[\"string1.txt\", string1],\n",
    "                      [\"string2.txt\", string2],\n",
    "                      [\"string3.txt\", string3],\n",
    "                      [\"string4.txt\", string4],\n",
    "                      [\"string5.txt\", string5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "76519498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Rank #1 (270 distance): string5.txt: There was a time when this wouldn't have bothered ...\",\n",
       " 'Rank #2 (285 distance): string1.txt: He slowly poured the drink over a large chunk of i...',\n",
       " 'Rank #3 (287 distance): string4.txt: The shades were closed keeping the room dark. Pete...',\n",
       " 'Rank #4 (289 distance): string2.txt: She never liked cleaning the sink. It was beyond h...',\n",
       " \"Rank #5 (300 distance): string3.txt: You're going to make a choice today that will have...\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Damerauâ€“Levenshtein distances:\n",
    "Dam_Lev_ranking(same_length_corpus, same_length_search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c197703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.88362546]\n",
      " [0.88362546 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Once again, let's see the correlation between distances and lengths:\n",
    "same_D_L_distances = [285, 289, 300, 287, 270]\n",
    "same_string_lengths = []\n",
    "same_length_corpus_strings = [x[1] for x in same_length_corpus]\n",
    "for i in range(len(same_D_L_distances)):\n",
    "    same_string_lengths.append(len(same_length_corpus_strings[i]))\n",
    "print(np.corrcoef(same_D_L_distances, same_string_lengths))\n",
    "# Even at small differences in lengths, these small differences are significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af3e9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (5.47733 distance): string1.txt: he slowly poured the drink over a large chunk of i...',\n",
       " 'Rank #2 (3.88784 distance): string4.txt: the shades were closed keeping the room dark peter...',\n",
       " 'Rank #3 (2.01467 distance): string5.txt: there was a time when this wouldnt have bothered h...',\n",
       " 'Rank #4 (1.30156 distance): string2.txt: she never liked cleaning the sink it was beyond he...',\n",
       " 'Rank #5 (0.90745 distance): string3.txt: youre going to make a choice today that will have ...']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dot-product ranks:\n",
    "dot_product_matrix(same_length_corpus, same_length_search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9552a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.07805612]\n",
      " [-0.07805612  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Their correlations:\n",
    "same_dot_product_distances = [5.47733, 1.30156, 0.90745, 3.88784, 2.01467]\n",
    "print(np.corrcoef(same_dot_product_distances, same_string_lengths))\n",
    "# There is no correlation between the dot product distances and the string lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcb4bb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank #1 (16.4607 distance): string1.txt: he slowly poured the drink over a large chunk of i...',\n",
       " 'Rank #2 (16.7552 distance): string4.txt: the shades were closed keeping the room dark peter...',\n",
       " 'Rank #3 (16.9688 distance): string2.txt: she never liked cleaning the sink it was beyond he...',\n",
       " 'Rank #4 (17.0178 distance): string5.txt: there was a time when this wouldnt have bothered h...',\n",
       " 'Rank #5 (22.7794 distance): string3.txt: youre going to make a choice today that will have ...']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Euclidean distances:\n",
    "Euclidean_distance(same_length_corpus, same_length_search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12406640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.56050713]\n",
      " [0.56050713 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Their correlations:\n",
    "same_Euclidean_distances = [16.4607, 16.9688, 22.7794, 16.7552, 17.0178]\n",
    "print(np.corrcoef(same_Euclidean_distances, same_string_lengths))\n",
    "# Now there is only a weak correlation between Euclidean distances and string lengths\n",
    "# It is also interesting to see, that now the results are almost the same for the\n",
    "# dot product and Euclidean ranks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f2f4914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User inputs should be string. We converted the values that aren't.\n",
      "Search string should be string. We converted it to string.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Rank #1 (2 distance): Test string: 55']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = [[\"Test string\", 55]]\n",
    "test_search = 115\n",
    "Dam_Lev_ranking(test_corpus, test_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
